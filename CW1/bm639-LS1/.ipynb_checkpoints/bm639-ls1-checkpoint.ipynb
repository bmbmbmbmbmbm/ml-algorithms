{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbours ): 1\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "kNN %): 100.0 \n",
      "\n",
      "neighbours ): 2\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "kNN %): 100.0 \n",
      "\n",
      "neighbours ): 3\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "kNN %): 100.0 \n",
      "\n",
      "neighbours ): 4\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [0 0 0 6]]\n",
      "kNN %): 100.0 \n",
      "\n",
      "neighbours ): 5\n",
      "[[4 0 0 3]\n",
      " [0 2 0 0]\n",
      " [0 3 0 0]\n",
      " [0 0 0 6]]\n",
      "kNN %): 66.66666666666666 \n",
      "\n",
      "neighbours ): 6\n",
      "[[4 0 0 3]\n",
      " [0 2 0 0]\n",
      " [0 3 0 0]\n",
      " [0 1 0 5]]\n",
      "kNN %): 61.111111111111114 \n",
      "\n",
      "neighbours ): 7\n",
      "[[2 0 0 5]\n",
      " [0 2 0 0]\n",
      " [0 2 0 1]\n",
      " [0 0 0 6]]\n",
      "kNN %): 55.55555555555556 \n",
      "\n",
      "neighbours ): 8\n",
      "[[2 0 0 5]\n",
      " [0 2 0 0]\n",
      " [0 2 0 1]\n",
      " [0 2 0 4]]\n",
      "kNN %): 44.44444444444444 \n",
      "\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [2 0 0 4]]\n",
      "GNB %): 88.88888888888889\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics \n",
    "\n",
    "# Q1\n",
    "\n",
    "fruit = pd.read_table(\"fruit_data_with_colors.txt\");\n",
    "fruit.head()\n",
    "\n",
    "fruit_vector=fruit[[\"mass\",\"width\",\"height\",\"color_score\",\"fruit_name\"]]\n",
    "fruit_vector.head()\n",
    "\n",
    "X = fruit_vector.iloc[:,:-1].values\n",
    "y = fruit_vector.iloc[:,4].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4321)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Q2\n",
    "\n",
    "for nn in range(1, 9): \n",
    "    classifier = KNeighborsClassifier(n_neighbors=nn)  \n",
    "    print(\"neighbours ):\",nn)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    print(\"kNN %):\", metrics.accuracy_score(y_test, y_pred)*100, \"\\n\")\n",
    "\n",
    "# Q3\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "GaussianNB()\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"GNB %):\", metrics.accuracy_score(y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple apple\n",
      "orange orange\n",
      "apple orange\n",
      "apple apple\n",
      "apple orange\n",
      "mandarin mandarin\n",
      "apple apple\n",
      "lemon lemon\n",
      "orange orange\n",
      "orange orange\n",
      "apple apple\n",
      "orange orange\n",
      "apple apple\n",
      "lemon lemon\n",
      "mandarin mandarin\n",
      "apple apple\n",
      "apple apple\n",
      "mandarin mandarin\n",
      "[[7 0 0 0]\n",
      " [0 2 0 0]\n",
      " [0 0 3 0]\n",
      " [2 0 0 4]]\n",
      "accuracy:  88.88888888888889\n"
     ]
    }
   ],
   "source": [
    "# Q4\n",
    "\n",
    "def fit(x_set, y_set):\n",
    "    df = pd.DataFrame(x_set)\n",
    "    mean = df.groupby(by=y_set).mean()\n",
    "    var = df.groupby(by=y_set).var()\n",
    "    return mean, var\n",
    "\n",
    "def gnb_calc(x_val, x_mean, x_var):\n",
    "    eq_pt1 = 1/(np.sqrt(2 * np.pi * x_var))\n",
    "    expon = np.exp(-(((x_val - x_mean) ** 2) / (2 * x_var)))\n",
    "    prob = eq_pt1 * expon\n",
    "    return prob\n",
    "\n",
    "def calc_prior(classifier, dataset):\n",
    "    count = 0;\n",
    "    total = len(dataset)\n",
    "    for i in range(total):\n",
    "        if dataset[i] == classifier:\n",
    "            count += 1\n",
    "    return count / total\n",
    "\n",
    "def mv_pairs_by_class(mean, var, y_train):\n",
    "    mv_temp = []\n",
    "    m = np.array(mean)\n",
    "    v = np.array(var)\n",
    "    \n",
    "    for i in range(len(mean)):\n",
    "        m_row = m[i]\n",
    "        v_row = v[i]\n",
    "        for index, value in enumerate(m_row):\n",
    "            mean = value\n",
    "            var = v_row[index]\n",
    "            mv_temp.append([mean, var])\n",
    "    mv_pairings = np.array(mv_temp)\n",
    "    n_class = len(np.unique(y_train))\n",
    "    s = np.vsplit(mv_pairings, n_class)\n",
    "    return s\n",
    "\n",
    "def classify(x_test, classes, mv_pairs, priors):\n",
    "    p_temp = []\n",
    "    for i in range(len(classes)):\n",
    "        a_class = mv_pairs[i]\n",
    "        for j in range(len(a_class)):\n",
    "            class_x_mean = a_class[j][0]\n",
    "            class_x_var = a_class[j][1]\n",
    "            x_value = x_test[j]\n",
    "            p_temp.append([gnb_calc(x_value, class_x_mean, class_x_var)])\n",
    "    prob = np.array(p_temp)\n",
    "    prob_class = np.vsplit(prob, len(classes))\n",
    "    j = 0\n",
    "    final_probs = []\n",
    "    for i in prob_class:\n",
    "        class_prob = np.prod(i) * priors[j]\n",
    "        final_probs.append(class_prob)\n",
    "        j += 1\n",
    "    \n",
    "    index = final_probs.index(max(final_probs))\n",
    "    return classes[index]\n",
    "    \n",
    "\n",
    "def GNB(x_train, x_test, y_train, y_test):\n",
    "    \n",
    "    mean, var = fit(x_train, y_train)\n",
    "    mv_pairs = mv_pairs_by_class(mean, var, y_train)\n",
    "    \n",
    "    classes = np.unique(y_train)\n",
    "    priors = []\n",
    "    for i in range(len(classes)):\n",
    "        priors.append(calc_prior(classes[i], y_train))\n",
    "    \n",
    "    results = []\n",
    "    count = 0\n",
    "    for i in range(len(x_test)):\n",
    "        results.append(classify(x_test[i], classes, mv_pairs, priors))\n",
    "        print(results[i], y_test[i])\n",
    "        if results[i] == y_test[i]:\n",
    "            count += 1\n",
    "    accuracy = (count / len(x_test)) * 100\n",
    "    print(confusion_matrix(y_test, results))\n",
    "    print(\"accuracy: \", accuracy)\n",
    "    \n",
    "GNB(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
